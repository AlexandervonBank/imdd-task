{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a SNN Demapper with Receptive-field Encoding\n",
    "\n",
    "More details can be found in [E. Arnold et al., “Spiking neural network nonlinear\n",
    "demapping on neuromorphic hardware for IM/DD optical communication”](https://ieeexplore.ieee.org/abstract/document/10059327/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import norse.torch as norse\n",
    "\n",
    "import sys \n",
    "sys.path.insert(0, \"/home/avb/CEL/Programme/imdd-halde/src\") \n",
    "from IMDD import PAM4IMDD, IMDDModel, IMDDParams, helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receptive-field Encoding\n",
    "\n",
    "One question when training a spiking demapper is how to best translate a chunk of real-valued data into a spiking representation in an efficient way.\n",
    "The receptive-field encoding translates each samples $y_k$ in the chunk to a set of $K$ spiking neurons.\n",
    "Each neuron has a `reference_point` assigned and its spike time is determined by the distance of $y_k$ to the given reference value.\n",
    "This results in a spatio-temporal encoding with $K$ neurons per sample $k$.\n",
    "\n",
    "We first create an IMDD link to generate data in order to visualize the input encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Send symbols:\n",
      " tensor([3, 1, 1,  ..., 1, 0, 1]) torch.Size([10000])\n",
      "Received data (chunked):\n",
      " tensor([[4.9853, 4.0772, 2.4113,  ..., 3.5843, 2.9625, 1.4257],\n",
      "        [5.1387, 4.9853, 4.0772,  ..., 4.0490, 3.5843, 2.9625],\n",
      "        [3.6973, 5.1387, 4.9853,  ..., 3.8416, 4.0490, 3.5843],\n",
      "        ...,\n",
      "        [4.5167, 4.7778, 1.2447,  ..., 1.7181, 1.0852, 4.8870],\n",
      "        [2.4113, 4.5167, 4.7778,  ..., 1.4257, 1.7181, 1.0852],\n",
      "        [4.0772, 2.4113, 4.5167,  ..., 2.9625, 1.4257, 1.7181]]) torch.Size([10000, 21])\n"
     ]
    }
   ],
   "source": [
    "params = IMDDParams(\n",
    "    N=10000,\n",
    "    n_taps=21,\n",
    "    alphabet=torch.tensor([0., 1., np.sqrt(2), np.sqrt(3)]),\n",
    "    oversampling_factor=3,\n",
    "    baudrate=50*1e9,\n",
    "    wavelength=0.000001550,\n",
    "    dispersion_parameter=-0.000017,\n",
    "    fiber_length=5000,\n",
    "    noise_power_gain_db=20.,\n",
    "    roll_off=0.2,\n",
    "    bias=0.25)\n",
    "link = IMDDModel(params)\n",
    "\n",
    "## Generate some data\n",
    "# Samples to send\n",
    "samples = link.source()\n",
    "print(\"Send symbols:\\n\", samples, samples.shape)\n",
    "\n",
    "# Received samples\n",
    "chunks = link(samples)\n",
    "print(\"Received data (chunked):\\n\", chunks, chunks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an instance of the `ReceptiveFieldEncoder`. The encoding is defined by the `references` which we choose to be $10$ values equdistantly distributed in $[0, 7]$. The distance $y_k - \\Chi_i$ is scaled by `scaling`. We neglect spikes which are later than `cutoff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wordlenght of the quantizer\n",
    "K = 8\n",
    "#Maximum input value of the quantizer\n",
    "XMAX = 4\n",
    "\n",
    "# Time resolution of encoding and SNN\n",
    "dt = 1e-3\n",
    "time_length = 0.01  # s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIT_MAPPER:\n",
    "    ###### class global ######\n",
    "\n",
    "    ####### Functions ########\n",
    "    def __init__(self, w, device):\n",
    "        self.change(w,device);\n",
    "\n",
    "    def change(self,w,device):\n",
    "        if(w <= 0):\n",
    "            print(\"w has to be larger than 0\");\n",
    "            quit();\n",
    "        else:\n",
    "            self.__wordlenght = w;\n",
    "\n",
    "        self.__device = device\n",
    "\n",
    "        self.__map_mat = torch.linspace(0,self.__wordlenght-1,self.__wordlenght).to(self.__device)\n",
    "        self.__map_mat = 2**self.__map_mat\n",
    "\n",
    "    def give_wordlenght(self):\n",
    "        return self.__wordlenght;\n",
    "    def give_device(self):\n",
    "        return self.__device;\n",
    "\n",
    "    def map(self,bits):\n",
    "        numbers = self.__map_mat @ torch.flip(bits,dims=[1]).T\n",
    "        return numbers\n",
    " \n",
    "    def demap(self,numbers):\n",
    "        orig_shape = numbers.shape\n",
    "        numbers = numbers.flatten()\n",
    "        bit_list = [(numbers >> shift_ind) & 1 for shift_ind in range(self.__wordlenght)] # little endian\n",
    "        bit_list.reverse() # big endian\n",
    "        bits = torch.zeros((self.__wordlenght,numbers.shape[0]),device=self.__device)\n",
    "        for n in range(len(bit_list)):\n",
    "            bits[n] = bit_list[n]\n",
    "        bits = bits.T\n",
    "    \n",
    "        bits = bits.unflatten(0,(orig_shape))\n",
    "\n",
    "        return bits\n",
    "        \n",
    "def midtread_binary_unipolar(x,w,x_max):\n",
    "    x = torch.clip(x,0,x_max)\n",
    "    Delta_x = x_max / (2**(w));\n",
    "    xh_uniform_midtread = torch.floor(torch.abs(x)/Delta_x+0.5);   #Select class from +/- 2**w-1/2\n",
    "    xh_uniform_midtread = torch.clip(xh_uniform_midtread,0,2**w-1);        #Clip to 2**w-1\n",
    "    xh_uniform_midtread = torch.ceil(xh_uniform_midtread).int();                 #Round up\n",
    "    return Delta_x,xh_uniform_midtread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ternary_Encoder(torch.nn.Module):\n",
    "    \"\"\" Class implementing the transmitter model \"\"\"\n",
    "\n",
    "    def __init__(self, wordlen=8, time=10, maximum_input_absolute = 4, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.w = wordlen\n",
    "        self.T = time\n",
    "        self.xmax = maximum_input_absolute\n",
    "        self.device = device\n",
    "        self.bitmap = BIT_MAPPER(self.w,self.device)\n",
    "\n",
    "    def forward(self,recv_symbols):\n",
    "        rx = recv_symbols - torch.mean(recv_symbols)\n",
    "        d_x,recv_q = midtread_binary_unipolar(torch.abs(rx),self.w,self.xmax)\n",
    "        binary = self.bitmap.demap(recv_q)\n",
    "        sign = torch.permute(torch.sign(rx).repeat(self.w,1,1),(1,2,0))\n",
    "        tern_in_sym = binary*sign\n",
    "        inputs = tern_in_sym.reshape( (1,tern_in_sym.shape[0],-1) )\n",
    "\n",
    "        inputs = torch.vstack( (inputs,torch.zeros( (self.T-1,inputs.shape[1],inputs.shape[2]), device=self.device)) )\n",
    "\n",
    "        return inputs\n",
    "\n",
    "\n",
    "encoder = Ternary_Encoder(wordlen=K, time=int(time_length//dt), maximum_input_absolute = XMAX, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we encode the 10 first chunks into binary spike tensors. The first dimension in the resulting data is the time axis, which is 60, corresponding to 30 ms. This becomes clearer in the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spikes:\n",
      " tensor([[[ 1.,  0.,  0.,  ..., -0., -1., -0.],\n",
      "         [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ..., -0., -1., -1.],\n",
      "         [ 0.,  1.,  0.,  ..., -1., -0., -0.],\n",
      "         [ 0.,  1.,  1.,  ..., -1., -0., -0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
      "\n",
      "        [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         ...,\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "         [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]]) torch.Size([10, 10, 168])\n"
     ]
    }
   ],
   "source": [
    "spikes = encoder(chunks[:10])  # first ten samples\n",
    "print(\"Spikes:\\n\", spikes, spikes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert time-dense spikes into event-based spikes\n",
    "events = torch.nonzero(spikes[:, 0])\n",
    "time = np.linspace(0, time_length, int(time_length / dt))\n",
    "\n",
    "fig, axes = plt.subplots(1)\n",
    "axes.set_xlim(-0.0001, time_length)\n",
    "axes.set_ylim(0, params.n_taps * K)\n",
    "axes.set_xlabel(\"$t$ [ms]\")\n",
    "axes.set_ylabel(\"input neuron $i$\")\n",
    "axes.scatter(events[:, 0] * dt, events[:, 1], s=5, color=\"black\")\n",
    "axes.vlines(1.1*time_length, 0, params.n_taps * K, color=\"blue\", ls=\":\")\n",
    "for i in range(7):\n",
    "    axes.hlines(10 * (i + 1), 0, 0.015, color=\"grey\", lw=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNN_Perceptron_Equalizer(torch.nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, output_features,encoder,device, dt=0.001):\n",
    "        super(SNN_Perceptron_Equalizer, self).__init__()\n",
    "        self.device = device;\n",
    "\n",
    "        self.encoder = encoder\n",
    "\n",
    "        self.input_features  =  input_features\n",
    "        self.hidden_features =  hidden_features\n",
    "        self.output_features =  output_features\n",
    "\n",
    "        self.dt = dt\n",
    "\n",
    "        self.p  = norse.LIFParameters(\n",
    "                    alpha       = torch.full((self.hidden_features,), torch.as_tensor(100.0)).to(device),\n",
    "                    v_th        = torch.full((self.hidden_features,), torch.as_tensor(  1.0)).to(device),\n",
    "                    v_leak      = torch.tensor(0.0).to(device),\n",
    "                    v_reset     = torch.full((self.hidden_features,), torch.as_tensor(  0.0)).to(device),\n",
    "                    tau_mem_inv = torch.full((self.hidden_features,), torch.as_tensor( 100.0)).to(device),\n",
    "                    tau_syn_inv = torch.full((self.hidden_features,), torch.as_tensor( 200.0)).to(device))\n",
    "        \n",
    "        self.input_layer    = torch.nn.Linear(self.input_features        , self.hidden_features,bias=False).to(device);\n",
    "        self.LIFRec_layer   = norse.LIFRecurrentCell(self.hidden_features, self.hidden_features,p=self.p,dt=dt,autapses=False).to(device);\n",
    "        self.output_layer   = torch.nn.Linear(self.hidden_features       , self.output_features,bias=True).to(device);\n",
    "    \n",
    "    def __decode_sum(self,x):\n",
    "        x = torch.sum(x,0);\n",
    "        return x\n",
    "\n",
    "    def forward(self, in_val):\n",
    "        #States of the neurons\n",
    "        state = None\n",
    "\n",
    "        x = self.encoder(in_val)\n",
    "\n",
    "        seq_length,batch_size,_ = x.shape\n",
    "\n",
    "        self.LIFRec_spikes  = torch.zeros(x.shape[0], x.shape[1], self.hidden_features, device=self.device)\n",
    "        z_rec          = torch.zeros(x.shape[1], self.hidden_features, device=self.device)\n",
    "\n",
    "        out = torch.zeros(x.shape[0], x.shape[1], self.output_features, device=self.device)\n",
    "\n",
    "        for ts in range(seq_length):\n",
    "            z               =  self.input_layer(x[ts,:,:]);\n",
    "            z,state            =  self.LIFRec_layer(z,state);\n",
    "            self.LIFRec_spikes[ts,:,:]  = z;\n",
    "            z               =  self.output_layer(z)\n",
    "            \n",
    "            out[ts][:][:]   =  z\n",
    "\n",
    "        hidden_z = self.LIFRec_spikes;\n",
    "        spikerate = torch.sum(hidden_z)/(hidden_z.shape[0]*hidden_z.shape[1]*hidden_z.shape[2])\n",
    "        \n",
    "        z = self.__decode_sum(out)\n",
    "        return z, spikerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stats(loss: torch.Tensor, pred: torch.Tensor, data: torch.Tensor):\n",
    "    ber = helpers.bit_error_rate(data, pred, False)\n",
    "    acc = helpers.accuracy(data, pred, False)\n",
    "    count = torch.count_nonzero(torch.argmax(pred, 1) != data)\n",
    "    return ber, acc, count\n",
    "\n",
    "\n",
    "def train(dataloader, optimizer, loss_fn, demapper, device):\n",
    "    loss, acc, ber = [], [], []\n",
    "\n",
    "    for i, (data, target) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        pred_b,_ = demapper(data)\n",
    "        loss_b = loss_fn(pred_b, target)\n",
    "\n",
    "        # Optimize\n",
    "        loss_b.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get stats\n",
    "        ber_b, acc_b, _ = stats(loss_b, pred_b, target)\n",
    "\n",
    "        # Accumualte\n",
    "        loss.append(loss_b.detach())\n",
    "        acc.append(acc_b)\n",
    "        ber.append(ber_b)\n",
    "\n",
    "    return (torch.stack(loss).reshape(-1).mean(),\n",
    "            np.stack(acc).reshape(-1).mean(),\n",
    "            np.stack(ber).reshape(-1).mean())\n",
    "\n",
    "\n",
    "def test(dataloader, demapper, loss_fn, device, min_false_symbols, max_test_epochs):\n",
    "    loss, acc, ber, n_false = [], [], [], 0\n",
    "\n",
    "    for epoch in range(max_test_epochs):\n",
    "        for i, (data, target) in enumerate(dataloader):\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            pred_b,_ = demapper(data)\n",
    "            loss_b = loss_fn(pred_b, target)\n",
    "\n",
    "            ber_b, acc_b, count = stats(loss_b, pred_b, target)\n",
    "\n",
    "            loss.append(loss_b.detach())\n",
    "            acc.append(acc_b)\n",
    "            ber.append(ber_b)\n",
    "\n",
    "            n_false += count\n",
    "\n",
    "        if n_false >= min_false_symbols:\n",
    "            break\n",
    "\n",
    "    return (torch.stack(loss).reshape(-1).mean(),\n",
    "            np.stack(acc).reshape(-1).mean(),\n",
    "            np.stack(ber).reshape(-1).mean(), n_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cpu\n",
      "SNR: 17\n",
      "17 dB\n",
      "Training Epoch=0, loss=1.4092, ber=0.4950500, acc=0.2507\n",
      "20.0 dB\n",
      "Evaluation, val_loss=1.3909, val_ber=0.5033000, val_acc=0.2477, n_false=7523\n",
      "17 dB\n",
      "Training Epoch=100, loss=0.2171, ber=0.0444500, acc=0.9111\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.1373, val_ber=0.0241500, val_acc=0.9517, n_false=1449\n",
      "17 dB\n",
      "Training Epoch=200, loss=0.1914, ber=0.0381500, acc=0.9237\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.1157, val_ber=0.0199000, val_acc=0.9602, n_false=1194\n",
      "17 dB\n",
      "Training Epoch=300, loss=0.1786, ber=0.0364500, acc=0.9271\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0969, val_ber=0.0158375, val_acc=0.9683, n_false=1267\n",
      "17 dB\n",
      "Training Epoch=400, loss=0.1488, ber=0.0281000, acc=0.9438\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0710, val_ber=0.0111500, val_acc=0.9777, n_false=1115\n",
      "17 dB\n",
      "Training Epoch=500, loss=0.1639, ber=0.0310000, acc=0.9380\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0621, val_ber=0.0094500, val_acc=0.9811, n_false=1134\n",
      "17 dB\n",
      "Training Epoch=600, loss=0.1341, ber=0.0265000, acc=0.9470\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0571, val_ber=0.0082286, val_acc=0.9835, n_false=1152\n",
      "17 dB\n",
      "Training Epoch=700, loss=0.1320, ber=0.0245500, acc=0.9509\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0492, val_ber=0.0075429, val_acc=0.9849, n_false=1056\n",
      "17 dB\n",
      "Training Epoch=800, loss=0.1212, ber=0.0224500, acc=0.9551\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0562, val_ber=0.0090000, val_acc=0.9820, n_false=1080\n",
      "17 dB\n",
      "Training Epoch=900, loss=0.1300, ber=0.0248000, acc=0.9504\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0447, val_ber=0.0066125, val_acc=0.9868, n_false=1058\n",
      "17 dB\n",
      "Training Epoch=1000, loss=0.1347, ber=0.0267500, acc=0.9465\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0431, val_ber=0.0059778, val_acc=0.9880, n_false=1076\n",
      "17 dB\n",
      "Training Epoch=1100, loss=0.1195, ber=0.0234000, acc=0.9532\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0368, val_ber=0.0050950, val_acc=0.9898, n_false=1019\n",
      "17 dB\n",
      "Training Epoch=1200, loss=0.0961, ber=0.0181000, acc=0.9638\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0303, val_ber=0.0042292, val_acc=0.9915, n_false=1015\n",
      "17 dB\n",
      "Training Epoch=1300, loss=0.1026, ber=0.0184500, acc=0.9631\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0304, val_ber=0.0041792, val_acc=0.9916, n_false=1003\n",
      "17 dB\n",
      "Training Epoch=1400, loss=0.1067, ber=0.0202500, acc=0.9595\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0297, val_ber=0.0040154, val_acc=0.9920, n_false=1044\n",
      "17 dB\n",
      "Training Epoch=1500, loss=0.0940, ber=0.0170500, acc=0.9659\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0264, val_ber=0.0036000, val_acc=0.9928, n_false=1008\n",
      "17 dB\n",
      "Training Epoch=1600, loss=0.0888, ber=0.0171500, acc=0.9657\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0341, val_ber=0.0055889, val_acc=0.9888, n_false=1006\n",
      "17 dB\n",
      "Training Epoch=1700, loss=0.0901, ber=0.0167000, acc=0.9666\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0252, val_ber=0.0032937, val_acc=0.9934, n_false=1054\n",
      "17 dB\n",
      "Training Epoch=1800, loss=0.0941, ber=0.0176000, acc=0.9648\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0254, val_ber=0.0035067, val_acc=0.9930, n_false=1052\n",
      "17 dB\n",
      "Training Epoch=1900, loss=0.0839, ber=0.0152500, acc=0.9695\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0259, val_ber=0.0035100, val_acc=0.9930, n_false=1053\n",
      "17 dB\n",
      "Training Epoch=2000, loss=0.1021, ber=0.0195500, acc=0.9609\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0340, val_ber=0.0054100, val_acc=0.9892, n_false=1082\n",
      "17 dB\n",
      "Training Epoch=2100, loss=0.0806, ber=0.0155000, acc=0.9690\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0208, val_ber=0.0025575, val_acc=0.9949, n_false=1023\n",
      "17 dB\n",
      "Training Epoch=2200, loss=0.0782, ber=0.0148500, acc=0.9703\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0268, val_ber=0.0037893, val_acc=0.9924, n_false=1061\n",
      "17 dB\n",
      "Training Epoch=2300, loss=0.0905, ber=0.0171000, acc=0.9659\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0215, val_ber=0.0028083, val_acc=0.9944, n_false=1011\n",
      "17 dB\n",
      "Training Epoch=2400, loss=0.0898, ber=0.0176500, acc=0.9647\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0209, val_ber=0.0028667, val_acc=0.9943, n_false=1032\n",
      "17 dB\n",
      "Training Epoch=2500, loss=0.0887, ber=0.0174500, acc=0.9651\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0201, val_ber=0.0025900, val_acc=0.9948, n_false=1036\n",
      "17 dB\n",
      "Training Epoch=2600, loss=0.0828, ber=0.0161000, acc=0.9678\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0191, val_ber=0.0024048, val_acc=0.9952, n_false=1010\n",
      "17 dB\n",
      "Training Epoch=2700, loss=0.0871, ber=0.0168500, acc=0.9664\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0247, val_ber=0.0036200, val_acc=0.9928, n_false=1086\n",
      "17 dB\n",
      "Training Epoch=2800, loss=0.0713, ber=0.0138000, acc=0.9724\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0214, val_ber=0.0028806, val_acc=0.9942, n_false=1037\n",
      "17 dB\n",
      "Training Epoch=2900, loss=0.0849, ber=0.0164000, acc=0.9672\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0190, val_ber=0.0023929, val_acc=0.9952, n_false=1005\n",
      "17 dB\n",
      "Training Epoch=3000, loss=0.0887, ber=0.0164500, acc=0.9671\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0200, val_ber=0.0027763, val_acc=0.9944, n_false=1055\n",
      "17 dB\n",
      "Training Epoch=3100, loss=0.0813, ber=0.0151500, acc=0.9697\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0189, val_ber=0.0025167, val_acc=0.9950, n_false=1057\n",
      "17 dB\n",
      "Training Epoch=3200, loss=0.0878, ber=0.0159000, acc=0.9682\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0179, val_ber=0.0022886, val_acc=0.9954, n_false=1006\n",
      "17 dB\n",
      "Training Epoch=3300, loss=0.0771, ber=0.0150000, acc=0.9700\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0190, val_ber=0.0024548, val_acc=0.9951, n_false=1031\n",
      "17 dB\n",
      "Training Epoch=3400, loss=0.0751, ber=0.0140500, acc=0.9719\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0179, val_ber=0.0023295, val_acc=0.9953, n_false=1025\n",
      "17 dB\n",
      "Training Epoch=3500, loss=0.0791, ber=0.0153000, acc=0.9694\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0169, val_ber=0.0020917, val_acc=0.9958, n_false=1004\n",
      "17 dB\n",
      "Training Epoch=3600, loss=0.0860, ber=0.0166000, acc=0.9668\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0216, val_ber=0.0030059, val_acc=0.9940, n_false=1022\n",
      "17 dB\n",
      "Training Epoch=3700, loss=0.0796, ber=0.0149500, acc=0.9701\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0177, val_ber=0.0022543, val_acc=0.9955, n_false=1037\n",
      "17 dB\n",
      "Training Epoch=3800, loss=0.0799, ber=0.0140000, acc=0.9720\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0169, val_ber=0.0021935, val_acc=0.9956, n_false=1009\n",
      "17 dB\n",
      "Training Epoch=3900, loss=0.0747, ber=0.0141000, acc=0.9718\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0175, val_ber=0.0022543, val_acc=0.9955, n_false=1037\n",
      "17 dB\n",
      "Training Epoch=4000, loss=0.0891, ber=0.0167500, acc=0.9665\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0206, val_ber=0.0027500, val_acc=0.9945, n_false=1045\n",
      "17 dB\n",
      "Training Epoch=4100, loss=0.0849, ber=0.0159000, acc=0.9682\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0183, val_ber=0.0025125, val_acc=0.9950, n_false=1005\n",
      "17 dB\n",
      "Training Epoch=4200, loss=0.0703, ber=0.0134000, acc=0.9732\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0169, val_ber=0.0021891, val_acc=0.9956, n_false=1007\n",
      "17 dB\n",
      "Training Epoch=4300, loss=0.1192, ber=0.0226000, acc=0.9548\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0196, val_ber=0.0027342, val_acc=0.9945, n_false=1039\n",
      "17 dB\n",
      "Training Epoch=4400, loss=0.0731, ber=0.0134500, acc=0.9731\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0169, val_ber=0.0021688, val_acc=0.9957, n_false=1041\n",
      "17 dB\n",
      "Training Epoch=4500, loss=0.0720, ber=0.0140000, acc=0.9720\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0251, val_ber=0.0040231, val_acc=0.9920, n_false=1046\n",
      "17 dB\n",
      "Training Epoch=4600, loss=0.0819, ber=0.0158000, acc=0.9684\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0167, val_ber=0.0020440, val_acc=0.9959, n_false=1022\n",
      "17 dB\n",
      "Training Epoch=4700, loss=0.0809, ber=0.0150000, acc=0.9700\n",
      "20.0 dB\n",
      "Evaluation, val_loss=0.0160, val_ber=0.0020240, val_acc=0.9960, n_false=1012\n"
     ]
    }
   ],
   "source": [
    "# The device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "# Training parameters\n",
    "batch_size_train = 10000 \n",
    "batch_size_val   = 10000 \n",
    "lr = 0.01\n",
    "epochs = 10000\n",
    "min_false_symbols = 1000\n",
    "max_test_epochs = 1000\n",
    "\n",
    "TRAINING_params = IMDDParams(   noise_power_gain_db=17., #We train at 17dB and evaluate at 20dB\n",
    "                                N=params.N,               #Rest stays as for the evaluation\n",
    "                                n_taps=params.n_taps,\n",
    "                                alphabet=params.alphabet,\n",
    "                                oversampling_factor=params.oversampling_factor,\n",
    "                                baudrate=params.baudrate,\n",
    "                                wavelength=params.wavelength,\n",
    "                                dispersion_parameter=params.dispersion_parameter,\n",
    "                                fiber_length=params.fiber_length,\n",
    "                                roll_off=params.roll_off,\n",
    "                                bias=params.bias)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "lif_demapper = SNN_Perceptron_Equalizer( K * params.n_taps,\n",
    "                                            80,\n",
    "                                            4,\n",
    "                                            encoder=encoder,\n",
    "                                            device=device, \n",
    "                                            dt = dt );\n",
    "\n",
    "# Dataset\n",
    "train_dataset = PAM4IMDD(TRAINING_params)\n",
    "dataset = PAM4IMDD(params)\n",
    "\n",
    "# Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size_train, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size_val, shuffle=True)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# The SNRs we train the demapper for\n",
    "op_point = 17\n",
    "\n",
    "model_dir = Path(\"./models\")\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"SNR: {op_point}\")\n",
    "# update SNR in Dataset\n",
    "train_dataset.simulator.params.noise_power_gain_db = op_point\n",
    "\n",
    "# New scheduler\n",
    "optimizer = torch.optim.Adam(lif_demapper.parameters(), lr=lr)\n",
    "\n",
    "# train for SNR\n",
    "# pbar = tqdm(total=epochs, unit=\"epoch\")\n",
    "val_data = torch.zeros((epochs // 10, 4))\n",
    "best_val_ber = np.inf\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc, train_ber = train(\n",
    "        train_loader, optimizer, loss_fn, lif_demapper, device)\n",
    "    #print(f\"Epoch={epoch}, loss={train_loss:.4f}, ber={train_ber:.7f}, \"\n",
    "    #      + f\"acc={train_acc:.4f}\")\n",
    "    if epoch % 100 == 0:\n",
    "        val_loss, val_acc, val_ber, n_false = test(\n",
    "            val_loader, lif_demapper, loss_fn, device, min_false_symbols,\n",
    "            max_test_epochs)\n",
    "\n",
    "        # Save best Demapper\n",
    "        if val_ber < best_val_ber:\n",
    "            torch.save(\n",
    "                lif_demapper.state_dict(), f\"./models/snr_{int(op_point)}.pt\")\n",
    "            best_val_ber = val_ber\n",
    "        print(str(train_dataset.simulator.params.noise_power_gain_db)+\" dB\")\n",
    "        print(f\"Training Epoch={epoch}, loss={train_loss:.4f}, ber={train_ber:.7f}, \"\n",
    "              + f\"acc={train_acc:.4f}\")\n",
    "        print(str(dataset.simulator.params.noise_power_gain_db)+\" dB\")\n",
    "        print(f\"Evaluation, val_loss={val_loss:.4f}, \"\n",
    "                + f\"val_ber={val_ber:.7f}, val_acc={val_acc:.4f}, \"\n",
    "                 + f\"n_false={n_false}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test demapper on independet data\n",
    "\n",
    "#SNRS to test the demapper\n",
    "snrs = torch.arange(15., 24., 1.)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "min_false_symbols = 2000\n",
    "\n",
    "# Dataset and loader\n",
    "dataset = PAM4IMDD(params)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size_val, shuffle=False)\n",
    "\n",
    "bers = np.zeros((snrs.shape[0], 3))\n",
    "\n",
    "for s, snr in enumerate(snrs):\n",
    "    # Set SNR in dataset\n",
    "    dataset.simulator.params.noise_power_gain_db = snr.item()\n",
    "\n",
    "    # Load best model for current SNR\n",
    "    state_dict = torch.load(f\"./models/snr_{int(op_point)}.pt\")\n",
    "    lif_demapper.load_state_dict(state_dict)\n",
    "\n",
    "    loss, acc, ber, n_false = [], [], [], 0\n",
    "\n",
    "    ber = []\n",
    "    while True:\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            pred_b,_ = lif_demapper(data)\n",
    "\n",
    "            ber_b = helpers.bit_error_rate(target, pred_b, False)\n",
    "            ber.append(ber_b)\n",
    "\n",
    "            n_false += torch.count_nonzero(torch.argmax(pred_b, 1) != target)\n",
    "\n",
    "        if n_false >= min_false_symbols:\n",
    "            break\n",
    "\n",
    "    bers[s, 0] = snr\n",
    "    bers[s, 1] = np.stack(ber).reshape(-1).mean()\n",
    "    bers[s, 2] = n_false\n",
    "\n",
    "    print(f\"Tested Demapper for {snr}. BER = {bers[s, 1]}, n_false = {n_false}\")\n",
    "\n",
    "np.save(\"test_bers.npy\", bers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first sample in last batch\n",
    "events = torch.nonzero(lif_demapper.LIFRec_spikes.detach().cpu()[:, 0, :]).numpy()\n",
    "\n",
    "_, axs = plt.subplots(nrows=1)\n",
    "axs.set_xlim(0, 10)\n",
    "axs.scatter(events[:, 0], events[:, 1])\n",
    "#axs[1].plot(lif_demapper.v_lif.detach().cpu().numpy()[:, 0])\n",
    "#axs[2].plot(lif_demapper.traces.detach().cpu().numpy()[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot BER-SNR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./test_bers.npy\")\n",
    "\n",
    "\n",
    "params = {'text.usetex' : True,\n",
    "          'font.size' : 8,\n",
    "          }\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "color = [\"#FAC90F\", \"#FA8D0F\", \"#0F69FA\", \"#7A6F45\"]\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(3.5, 2.7))\n",
    "axs.set_ylabel(\"BER\")\n",
    "axs.set_xlabel(\"$−10 \\log_{10}(\\sigma^2)$ [dB]\")\n",
    "axs.set_yscale(\"log\")\n",
    "axs.set_ylim(1e-4, 3e-2)\n",
    "axs.set_xlim(14.5, 22.5)\n",
    "axs.set_xticks(data[:, 0])\n",
    "axs.plot(data[:, 0], data[:, 1], lw=1, color=color[0], label=r\"7 tap SNN\")\n",
    "axs.scatter(data[:, 0], data[:, 1], color=color[0], s=10)\n",
    "axs.hlines(2e-3, 14.5, 22.5, color=\"grey\", ls=\"--\", label=\"KP4 FEC Threshold\")\n",
    "axs.grid(which=\"minor\", lw=0.5)\n",
    "axs.grid(which=\"major\", lw=0.7)\n",
    "axs.yaxis.set_label_coords(-0.1, 0.6)\n",
    "axs.legend(fontsize=9, handlelength=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./snr.pgf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_python",
   "language": "python",
   "name": "snn_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
